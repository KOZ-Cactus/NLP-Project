{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CX-8q3a-p-xD",
        "outputId": "fd777736-3848-4ad4-b3c8-2c340d243303"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import json\n",
        "import numpy as np\n",
        "import nltk\n",
        "from nltk.corpus import wordnet as wn\n",
        "nltk.download('wordnet')\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tItk1Ta3qydf",
        "outputId": "7de3ac42-e52b-49d4-87da-67b661630e6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q kaggle\n"
      ],
      "metadata": {
        "id": "v9hSU6TXr5Ms"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp \"/content/drive/My Drive/Colab Notebooks/nlp project/kaggle.json\" ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n"
      ],
      "metadata": {
        "id": "kw21qJwisH8D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d dfydata/wordnet-dictionary-thesaurus-files-in-csv-format\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FgX7VKlWsONA",
        "outputId": "1f821811-625d-448b-de6c-7ae6d4d1e3c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/dfydata/wordnet-dictionary-thesaurus-files-in-csv-format\n",
            "License(s): CC0-1.0\n",
            "Downloading wordnet-dictionary-thesaurus-files-in-csv-format.zip to /content\n",
            "  0% 0.00/11.1M [00:00<?, ?B/s]\n",
            "100% 11.1M/11.1M [00:00<00:00, 782MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q wordnet-dictionary-thesaurus-files-in-csv-format.zip\n"
      ],
      "metadata": {
        "id": "hfO3OBZdsQ3u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -1\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k4UQ_5N-sTDx",
        "outputId": "f4c8eec8-2f8b-49d6-b782-780ea72a2fc6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "drive\n",
            "sample_data\n",
            "WordNet-DictionaryThesaurus\n",
            "wordnet-dictionary-thesaurus-files-in-csv-format.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "syn_df = pd.read_csv('WordNet-DictionaryThesaurus/WordnetSynonyms.csv')\n",
        "ant_df = pd.read_csv('WordNet-DictionaryThesaurus/WordnetAntonyms.csv')\n",
        "hyp_df = pd.read_csv('WordNet-DictionaryThesaurus/WordnetHypernyms.csv')\n",
        "\n",
        "# hypo_df = pd.read_csv('WordNet-DictionaryThesaurus/WordnetHyponyms.csv')\n",
        "\n",
        "print(\"Synonyms sample:\\n\", syn_df.head(), \"\\n\")\n",
        "print(\"Antonyms sample:\\n\", ant_df.head(), \"\\n\")\n",
        "print(\"Hypernyms sample:\\n\", hyp_df.head(), \"\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xvwif95tsU4A",
        "outputId": "42a3f32a-795c-4118-b43c-7e01668c1367"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Synonyms sample:\n",
            "      Word  Count        POS                                           Synonyms\n",
            "0    a-ok      4  satellite                                             a-okay\n",
            "1  a-okay      6  satellite                                               a-ok\n",
            "2   a-one      5  satellite  ace;A-one;crack;first-rate;super;tiptop;topnot...\n",
            "3    a.m.      4  satellite                                      ante meridiem\n",
            "4    a.m.      4     adverb                                 ante meridiem;A.M. \n",
            "\n",
            "Antonyms sample:\n",
            "            Word  Count        POS      Antonyms\n",
            "0    a la carte     10  adjective  table d'hote\n",
            "1  a posteriori     12  adjective      a priori\n",
            "2  a posteriori     12     adverb      a priori\n",
            "3      a priori      8  adjective  a posteriori\n",
            "4      a priori      8     adverb  a posteriori \n",
            "\n",
            "Hypernyms sample:\n",
            "   lemma  Count part_of_speech hypernyms\n",
            "0     0      1           noun     digit\n",
            "1  0.22      4           noun   firearm\n",
            "2     1      1           noun     digit\n",
            "3     2      1           noun     digit\n",
            "4     3      1           noun     digit \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "synonyms_dict = {}\n",
        "antonyms_dict = {}\n",
        "hypernyms_dict = {}\n",
        "\n",
        "def clean_and_split(entry):\n",
        "    if not entry or entry == 'nan':\n",
        "        return set()\n",
        "    parts = entry.replace(';', '|').split('|')\n",
        "    return set(p.strip().lower() for p in parts if p.strip().isalpha())\n",
        "\n",
        "# --- Building synonyms_dict from WordnetSynonyms.csv ---\n",
        "for _, row in syn_df.iterrows():\n",
        "    word = str(row[\"Word\"]).strip().lower()\n",
        "    synonym_str = str(row[\"Synonyms\"]).strip().lower()\n",
        "    if not word or synonym_str == 'nan':\n",
        "        continue\n",
        "    synonyms = clean_and_split(synonym_str)\n",
        "    for syn in synonyms:\n",
        "        if syn != word:\n",
        "            synonyms_dict.setdefault(word, set()).add(syn)\n",
        "            synonyms_dict.setdefault(syn, set()).add(word)  # symmetric\n",
        "\n",
        "# --- Building antonyms_dict from WordnetAntonyms.csv ---\n",
        "for _, row in ant_df.iterrows():\n",
        "    word = str(row[\"Word\"]).strip().lower()\n",
        "    antonym_str = str(row[\"Antonyms\"]).strip().lower()\n",
        "    if not word or not antonym_str:\n",
        "        continue\n",
        "    antonyms = clean_and_split(antonym_str)\n",
        "    for ant in antonyms:\n",
        "        if ant != word:\n",
        "            antonyms_dict.setdefault(word, set()).add(ant)\n",
        "            antonyms_dict.setdefault(ant, set()).add(word)  # symmetric\n",
        "\n",
        "# --- Building hypernyms_dict from WordnetHypernyms.csv ---\n",
        "for _, row in hyp_df.iterrows():\n",
        "    word = str(row[\"lemma\"]).strip().lower()\n",
        "    hypernym_str = str(row[\"hypernyms\"]).strip().lower()\n",
        "    if not word or not word.isalpha() or not hypernym_str:\n",
        "        continue\n",
        "    hypernyms = clean_and_split(hypernym_str)\n",
        "    for hyper in hypernyms:\n",
        "        if hyper != word:\n",
        "            hypernyms_dict.setdefault(word, set()).add(hyper)\n",
        "\n",
        "print(f\"✅ Cleaned and loaded {len(synonyms_dict)} words with synonyms\")\n",
        "print(f\"✅ Cleaned and loaded {len(antonyms_dict)} words with antonyms\")\n",
        "print(f\"✅ Cleaned and loaded {len(hypernyms_dict)} words with hypernyms\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eYPleCCAtdnd",
        "outputId": "c5f5144f-315b-4b2c-ac20-3ecb13e4fe72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Cleaned and loaded 89157 words with synonyms\n",
            "✅ Cleaned and loaded 9816 words with antonyms\n",
            "✅ Cleaned and loaded 45256 words with hypernyms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"📌 Clean synonyms for 'smart':\", synonyms_dict.get(\"smart\", []))\n",
        "print(\"📌 Clean antonyms for 'hot':\", antonyms_dict.get(\"hot\", []))\n",
        "print(\"📌 Clean hypernyms for 'dog':\", hypernyms_dict.get(\"dog\", []))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Hgop6wVuAhw",
        "outputId": "6e66bf2a-503a-48a8-f8d8-d73f37ed6677"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📌 Clean synonyms for 'smart': {'hurt', 'smartness', 'fresh', 'chic', 'impertinent', 'ache', 'fresher', 'sassy', 'impudent', 'wise', 'voguish', 'aching', 'saucy', 'hurting', 'bright', 'smarting', 'overbold'}\n",
            "📌 Clean antonyms for 'hot': {'cold'}\n",
            "📌 Clean hypernyms for 'dog': {'villain', 'canine', 'pursue', 'chap', 'support', 'catch', 'sausage'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -q http://nlp.stanford.edu/data/glove.6B.zip\n",
        "!unzip -q glove.6B.zip -d glove/\n"
      ],
      "metadata": {
        "id": "uK9XEv2UuGGS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Building set of words used in our relations\n",
        "vocab_of_interest = set()\n",
        "\n",
        "# Including all base words (keys)\n",
        "vocab_of_interest.update(synonyms_dict.keys())\n",
        "vocab_of_interest.update(antonyms_dict.keys())\n",
        "vocab_of_interest.update(hypernyms_dict.keys())\n",
        "\n",
        "for rel_dict in [synonyms_dict, antonyms_dict, hypernyms_dict]:\n",
        "    for related_words in rel_dict.values():\n",
        "        vocab_of_interest.update(related_words)\n",
        "\n",
        "# Cleaning non-alphabetic entries\n",
        "vocab_of_interest = {w for w in vocab_of_interest if w.isalpha()}\n",
        "print(f\"🧠 Vocab of interest has {len(vocab_of_interest)} clean single-word entries.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SEtAjQBLvMq9",
        "outputId": "42be900b-2acd-46bb-c2be-ac6b01d2ee2a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🧠 Vocab of interest has 70232 clean single-word entries.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "glove_path = \"glove/glove.6B.100d.txt\"\n",
        "embedding_dim = 100\n",
        "word_vectors = {}\n",
        "\n",
        "with open(glove_path, 'r', encoding='utf8') as f:\n",
        "    for line in f:\n",
        "        parts = line.strip().split()\n",
        "        if len(parts) != embedding_dim + 1:\n",
        "            continue\n",
        "        word = parts[0]\n",
        "        if word in vocab_of_interest:\n",
        "            vec = np.array(parts[1:], dtype='float32')\n",
        "            word_vectors[word] = vec\n",
        "\n",
        "print(f\"✅ Loaded {len(word_vectors)} filtered word vectors.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2n6eYrjuvS3m",
        "outputId": "b2aab8f4-10fc-4df7-ced3-98b1d2151eff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Loaded 48623 filtered word vectors.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"📌 Vector for 'apple':\", word_vectors.get(\"apple\", \"Not found\"))\n",
        "print(\"📌 Vector shape:\", word_vectors[\"apple\"].shape if \"apple\" in word_vectors else \"N/A\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "030Xl9W7vTyG",
        "outputId": "59bfa4ac-2387-4178-ed1f-44129f7ca996"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📌 Vector for 'apple': [-0.5985    -0.46321    0.13001   -0.019576   0.4603    -0.3018\n",
            "  0.8977    -0.65634    0.66858   -0.49164    0.037557  -0.050889\n",
            "  0.6451    -0.53882   -0.3765    -0.04312    0.51384    0.17783\n",
            "  0.28596    0.92063   -0.49349   -0.48583    0.61321    0.78211\n",
            "  0.19254    0.91228   -0.055596  -0.12512   -0.65688    0.068557\n",
            "  0.55629    1.611     -0.0073642 -0.48879    0.45493    0.96105\n",
            " -0.063369   0.17432    0.9814    -1.3125    -0.15801   -0.54301\n",
            " -0.13888   -0.26146   -0.3691     0.26844   -0.24375   -0.19484\n",
            "  0.62583   -0.7377     0.38351   -0.75004   -0.39053    0.091498\n",
            " -0.36591   -1.4715    -0.45228    0.2256     1.1412    -0.38526\n",
            " -0.06716    0.57288   -0.39191    0.31302   -0.29235   -0.96157\n",
            "  0.15154   -0.21659    0.25103    0.096967   0.2843     1.4296\n",
            " -0.50565   -0.51374   -0.47218    0.32036    0.023149   0.22623\n",
            " -0.09725    0.82126    0.92599   -1.0086    -0.38639    0.86408\n",
            " -1.206     -0.28528    0.2265    -0.38773    0.40879    0.59303\n",
            "  0.30769    0.83804   -0.63655   -0.44639   -0.43406   -0.79364\n",
            " -0.28675   -0.034398   1.3431     0.34904  ]\n",
            "📌 Vector shape: (100,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "def cosine_sim(vec1, vec2):\n",
        "    \"\"\"Compute cosine similarity between two vectors.\"\"\"\n",
        "    if vec1 is None or vec2 is None:\n",
        "        return 0.0\n",
        "    return cosine_sim(vec1.reshape(1, -1), vec2.reshape(1, -1))[0][0]\n",
        "\n",
        "def get_candidates_for_targets(target_words):\n",
        "    \"\"\"\n",
        "    Given a list of target words, gather a set of candidate clue words\n",
        "    that are related to these targets via synonyms or hypernyms.\n",
        "    \"\"\"\n",
        "    candidates = set()\n",
        "    for w in target_words:\n",
        "        w = w.lower()\n",
        "        if w in synonyms_dict:\n",
        "            candidates.update(synonyms_dict[w])\n",
        "        if w in hypernyms_dict:\n",
        "            candidates.update(hypernyms_dict[w])\n",
        "\n",
        "    candidates -= set([t.lower() for t in target_words])\n",
        "\n",
        "    filtered = set()\n",
        "    for c in candidates:\n",
        "        if ' ' in c:\n",
        "            continue\n",
        "        if c in word_vectors:\n",
        "            filtered.add(c)\n",
        "\n",
        "    return filtered\n",
        "\n",
        "sample_targets = [\"dog\", \"cat\"]\n",
        "print(\"🎯 Candidate clues for [dog, cat]:\", get_candidates_for_targets(sample_targets))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8PfCR74xvVWr",
        "outputId": "f95ecb07-6ec2-47e9-9a05-c5ce7e650940"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🎯 Candidate clues for [dog, cat]: {'tailing', 'spew', 'purging', 'bounder', 'click', 'chased', 'blackguard', 'chuck', 'detent', 'trailing', 'purge', 'tail', 'cad', 'vomit', 'stimulant', 'trail', 'barf', 'track', 'chase', 'hound', 'catch', 'kat', 'guy', 'khat', 'gossip', 'canine', 'ct', 'heel', 'sick', 'quat', 'weenie', 'hotdog', 'bozo', 'vomiting', 'frankfurter', 'regurgitate', 'honk', 'woman', 'tagged', 'dogging', 'villain', 'feline', 'caterpillar', 'wiener', 'frank', 'puke', 'casting', 'chap', 'retch', 'excrete', 'tails', 'dogged', 'puking', 'cast', 'flog', 'frump', 'man', 'disgorge', 'hombre', 'tracked', 'tracking', 'tag', 'qat', 'pursue', 'support', 'tailed', 'pawl', 'whip', 'sausage'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "class Board:\n",
        "    def __init__(self, words, first_team='blue'):\n",
        "        \"\"\"\n",
        "        Initialize the board with a given list of words and assign roles.\n",
        "        `words` is a list of unique words to be used on the board.\n",
        "        `first_team` is the team that has the extra word (typically 'blue' or 'red').\n",
        "        \"\"\"\n",
        "        assert len(words) >= 25, \"Need at least 25 words to populate the board.\"\n",
        "        board_words = random.sample(words, 25)\n",
        "\n",
        "        roles = ['blue'] * (9 if first_team == 'blue' else 8) \\\n",
        "              + ['red'] * (9 if first_team == 'red' else 8) \\\n",
        "              + ['neutral'] * 7 + ['assassin']\n",
        "        random.shuffle(roles)\n",
        "\n",
        "        self.word_roles = {word: roles[i] for i, word in enumerate(board_words)}\n",
        "        self.revealed = {word: False for word in board_words}\n",
        "        self.first_team = first_team\n",
        "\n",
        "    def reveal_word(self, word):\n",
        "        \"\"\"Mark a word as revealed (guessed).\"\"\"\n",
        "        if word in self.revealed:\n",
        "            self.revealed[word] = True\n",
        "\n",
        "    def get_role(self, word):\n",
        "        \"\"\"Get the secret role of a word (e.g., 'blue', 'red', 'neutral', 'assassin').\"\"\"\n",
        "        return self.word_roles.get(word, None)\n",
        "\n",
        "    def remaining_words(self, team=None):\n",
        "        \"\"\"Return list of unrevealed words, optionally filtered by team.\"\"\"\n",
        "        words = [w for w, rev in self.revealed.items() if not rev]\n",
        "        if team:\n",
        "            return [w for w in words if self.word_roles[w] == team]\n",
        "        return words\n",
        "\n",
        "    def all_words(self):\n",
        "        \"\"\"Return all board words (revealed or not).\"\"\"\n",
        "        return list(self.word_roles.keys())\n",
        "\n",
        "    def __str__(self):\n",
        "        \"\"\"For debugging: show all word roles (revealed or not).\"\"\"\n",
        "        return \"\\n\".join([f\"{w}: {self.word_roles[w]}{' [REVEALED]' if self.revealed[w] else ''}\" for w in self.word_roles])\n"
      ],
      "metadata": {
        "id": "U6n6ERKSwanq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "board_words = list(word_vectors.keys())\n",
        "test_board = Board(board_words, first_team='blue')\n",
        "\n",
        "print(\"🔹 Words assigned to roles:\")\n",
        "print(test_board)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h5SA6oIOzKlr",
        "outputId": "b7780219-5c35-45b9-ebaf-9f62f1fe14c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔹 Words assigned to roles:\n",
            "oversupply: blue\n",
            "birdcage: neutral\n",
            "agave: blue\n",
            "concentric: red\n",
            "beefeater: neutral\n",
            "cosmographer: red\n",
            "claudius: red\n",
            "obscenely: blue\n",
            "sheltered: neutral\n",
            "deviationist: neutral\n",
            "elmwood: red\n",
            "garcinia: blue\n",
            "katabatic: blue\n",
            "tolu: blue\n",
            "band: blue\n",
            "bodacious: blue\n",
            "prowl: red\n",
            "fbi: blue\n",
            "lodgepole: red\n",
            "bobwhite: assassin\n",
            "fireball: red\n",
            "misunderstood: neutral\n",
            "refilling: neutral\n",
            "conduction: neutral\n",
            "brainpower: red\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import wordnet as wn\n",
        "import random\n",
        "\n",
        "class ClueGenerator:\n",
        "    def __init__(self, embedding_dict):\n",
        "        self.embedding = embedding_dict\n",
        "\n",
        "    def score_clue(self, clue, target_words, other_words):\n",
        "        \"\"\"Score clue: high for closeness to targets, low for others.\"\"\"\n",
        "        vec_c = self.embedding.get(clue)\n",
        "        if vec_c is None:\n",
        "            return -float('inf')\n",
        "        pos_score = sum(\n",
        "            cosine_simy(vec_c.reshape(1, -1), self.embedding[t].reshape(1, -1))[0][0]\n",
        "            for t in target_words if t in self.embedding\n",
        "        )\n",
        "        neg_score = sum(\n",
        "            cosine_sim(vec_c.reshape(1, -1), self.embedding[o].reshape(1, -1))[0][0]\n",
        "            for o in other_words if o in self.embedding\n",
        "        )\n",
        "        return pos_score - neg_score\n",
        "\n",
        "    def generate_clue(self, board, team):\n",
        "        \"\"\"Generate a (clue, number) pair based on current board state.\"\"\"\n",
        "        team_words = board.remaining_words(team=team)\n",
        "        other_words = [w for w in board.remaining_words() if w not in team_words]\n",
        "        team_words = [w.lower() for w in team_words]\n",
        "        other_words = [w.lower() for w in other_words]\n",
        "\n",
        "\n",
        "        candidates = get_candidates_for_targets(team_words)\n",
        "        if not candidates:\n",
        "            # Fallback: using WordNet hypernyms\n",
        "            for w in team_words:\n",
        "                for syn in wn.synsets(w):\n",
        "                    for hyper in syn.hypernyms():\n",
        "                        candidates.add(hyper.lemmas()[0].name().lower())\n",
        "            if not candidates:\n",
        "                candidates = vocab_of_interest - set([w.lower() for w in board.word_roles.keys()])\n",
        "\n",
        "        # Step 2: filtering clues that are on board (illegal)\n",
        "        legal_candidates = [\n",
        "            c for c in candidates if c not in [w.lower() for w in board.word_roles.keys()]\n",
        "        ]\n",
        "\n",
        "        # Step 3: scoring and select the best clue\n",
        "        best_clue = None\n",
        "        best_score = -float('inf')\n",
        "        for clue in legal_candidates:\n",
        "            score = self.score_clue(clue, team_words, other_words)\n",
        "            if score > best_score:\n",
        "                best_score = score\n",
        "                best_clue = clue\n",
        "\n",
        "        # Step 4: counting how many targets the clue likely points to\n",
        "        number = 0\n",
        "        if best_clue:\n",
        "            vec_c = self.embedding.get(best_clue)\n",
        "            for t in team_words:\n",
        "                vec_t = self.embedding.get(t)\n",
        "                if vec_t is not None:\n",
        "                    sim = cosine_sim(vec_c.reshape(1, -1), vec_t.reshape(1, -1))[0][0]\n",
        "                    if sim >= 0.3:\n",
        "                        number += 1\n",
        "        else:\n",
        "            best_clue = random.choice(team_words)\n",
        "            number = 1\n",
        "\n",
        "        return best_clue, number\n"
      ],
      "metadata": {
        "id": "v__iazSAzMc8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cg = ClueGenerator(word_vectors)\n",
        "clue, num = cg.generate_clue(test_board, team='blue')\n",
        "print(f\"🧠 Suggested clue: '{clue}' for {num} word(s).\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5b9lcZfQzoFf",
        "outputId": "e124205c-1aab-40f6-dd13-527da098047c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🧠 Suggested clue: 'flood' for 0 word(s).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Guesser:\n",
        "    def __init__(self, embedding_dict):\n",
        "        self.embedding = embedding_dict\n",
        "\n",
        "    def guess_words(self, clue_word, number, board):\n",
        "        \"\"\"\n",
        "        Given a clue and a number, return a list of up to 'number' guesses for the board.\n",
        "        \"\"\"\n",
        "        clue_vec = self.embedding.get(clue_word)\n",
        "        if clue_vec is None:\n",
        "            return []\n",
        "\n",
        "        scores = []\n",
        "        for word, revealed in board.revealed.items():\n",
        "            if revealed:\n",
        "                continue\n",
        "            vec_w = self.embedding.get(word.lower())\n",
        "            if vec_w is None:\n",
        "                continue\n",
        "            sim = cosine_sim(clue_vec.reshape(1, -1), vec_w.reshape(1, -1))[0][0]\n",
        "            scores.append((sim, word))\n",
        "\n",
        "        scores.sort(reverse=True)\n",
        "        return [w for _, w in scores[:number]]\n"
      ],
      "metadata": {
        "id": "8EIdN2AXzp0C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clue_gen = ClueGenerator(word_vectors)\n",
        "guesser = Guesser(word_vectors)\n",
        "\n",
        "clue, number = clue_gen.generate_clue(test_board, team='blue')\n",
        "print(f\"🤖 Clue: '{clue}' ({number})\")\n",
        "\n",
        "guesses = guesser.guess_words(clue, number, test_board)\n",
        "print(\"🎯 Guesser's guesses:\", guesses)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z830JrDn0CrN",
        "outputId": "e1e8e771-d59a-4298-96a1-f00cbcfd4789"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🤖 Clue: 'flood' (0)\n",
            "🎯 Guesser's guesses: []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class RLClueAgent(ClueGenerator):\n",
        "    def __init__(self, embedding_dict):\n",
        "        super().__init__(embedding_dict)\n",
        "        #  bunu sonra ekle policy network, memory\n",
        "    def generate_clue(self, board, team):\n",
        "        #  bunu da RL policy here\n",
        "        return super().generate_clue(board, team)\n",
        "\n",
        "        #\n",
        "        # candidates = list(vocab_of_interest - set([w.lower() for w in board.word_roles.keys()]))\n",
        "        # if candidates:\n",
        "        #     return random.choice(candidates), 1\n",
        "        # else:\n",
        "        #     return super().generate_clue(board, team)\n"
      ],
      "metadata": {
        "id": "iDEaLodA0Era"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_words_list = [w for w in synonyms_dict.keys() if w in word_vectors]\n",
        "all_words_list = [w for w in all_words_list if ' ' not in w and '_' not in w]\n",
        "\n",
        "game_board = Board(words=all_words_list, first_team='blue')\n",
        "print(\"🧩 Game Board (Secret Roles Shown Below - Normally Hidden):\")\n",
        "print(game_board)\n",
        "\n",
        "rl_agent = RLClueAgent(word_vectors)\n",
        "guesser = Guesser(word_vectors)\n",
        "\n",
        "clue_word, clue_number = rl_agent.generate_clue(game_board, team='blue')\n",
        "print(f\"\\n🧠 Clue for BLUE team: \\\"{clue_word}\\\" with number {clue_number}\")\n",
        "\n",
        "guesses = guesser.guess_words(clue_word, clue_number, game_board)\n",
        "print(f\"\\n🎯 Guesser's guesses (up to {clue_number}): {guesses}\")\n",
        "\n",
        "for guess in guesses:\n",
        "    game_board.reveal_word(guess)\n",
        "    role = game_board.get_role(guess)\n",
        "    result = \"✅ CORRECT\" if role == 'blue' else (\"❌ OPPONENT\" if role == 'red' else \"⚠️ \" + role.upper())\n",
        "    print(f\"🔍 Guess \\\"{guess}\\\": {role.upper()} → {result}\")\n"
      ],
      "metadata": {
        "id": "snmBVY7T1V1o",
        "outputId": "05318efa-0aef-4231-83b5-a7ba87328fed",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🧩 Game Board (Secret Roles Shown Below - Normally Hidden):\n",
            "gobbler: assassin\n",
            "profusion: neutral\n",
            "jimmy: red\n",
            "releasing: blue\n",
            "pericardial: red\n",
            "tea: blue\n",
            "ascendent: red\n",
            "investiture: neutral\n",
            "colic: blue\n",
            "decapoda: red\n",
            "valorous: red\n",
            "biography: blue\n",
            "larch: blue\n",
            "roble: neutral\n",
            "mimic: red\n",
            "nonconformist: blue\n",
            "algeria: blue\n",
            "bikini: red\n",
            "rapture: red\n",
            "paspalum: neutral\n",
            "slickly: neutral\n",
            "bosomy: neutral\n",
            "caldron: blue\n",
            "grapple: blue\n",
            "willebrand: neutral\n",
            "\n",
            "🧠 Clue for BLUE team: \"issue\" with number 2\n",
            "\n",
            "🎯 Guesser's guesses (up to 2): ['releasing', 'biography']\n",
            "🔍 Guess \"releasing\": BLUE → ✅ CORRECT\n",
            "🔍 Guess \"biography\": BLUE → ✅ CORRECT\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preprocessing: Loading GloVe Embeddings\n"
      ],
      "metadata": {
        "id": "nfK17EfoPeE6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "embeddings = {}\n",
        "glove_path = \"glove/glove.6B.100d.txt\"\n",
        "with open(glove_path, 'r', encoding='utf-8') as f:\n",
        "    for line in f:\n",
        "        parts = line.strip().split()\n",
        "        word = parts[0]\n",
        "        vector = np.array(parts[1:], dtype=float)\n",
        "        embeddings[word] = vector\n",
        "\n",
        "print(f\"Loaded {len(embeddings)} word vectors.\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tvav_U1uPfU6",
        "outputId": "8a482e52-e8c5-4851-f99c-31dac152e6ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 400000 word vectors.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import numpy as np\n",
        "\n",
        "def cosine_sim(vec1, vec2):\n",
        "    \"\"\"\n",
        "    Compute cosine similarity between two vectors, ensuring both are 1D (100,).\n",
        "    Returns a float.\n",
        "    \"\"\"\n",
        "    vec1 = np.asarray(vec1).flatten()\n",
        "    vec2 = np.asarray(vec2).flatten()\n",
        "    return cosine_similarity(vec1.reshape(1, -1), vec2.reshape(1, -1))[0][0]\n"
      ],
      "metadata": {
        "id": "jsQuI6HBPhbu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Guesser:\n",
        "    def __init__(self, embeddings):\n",
        "        self.embeddings = embeddings  # dictionary of word -> vector\n",
        "\n",
        "    def predict_guesses(self, clue_word, clue_number, board):\n",
        "        key = clue_word.lower()\n",
        "        if key not in self.embeddings:\n",
        "            raise ValueError(f\"Clue word '{clue_word}' not found in embeddings.\")\n",
        "        clue_vec = self.embeddings[key]\n",
        "\n",
        "        unrevealed_words = board.get_unrevealed_words()\n",
        "        similarities = []\n",
        "        for word in unrevealed_words:\n",
        "            vec = self.embeddings.get(word.lower())\n",
        "            if vec is None:\n",
        "                continue\n",
        "            #  cosine similarity between clue and this board word\n",
        "            score = cosine_sim(clue_vec, vec)\n",
        "            similarities.append((word, score))\n",
        "        similarities.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "        top_n = clue_number if clue_number <= len(similarities) else len(similarities)\n",
        "        top_guesses = [word for word, score in similarities[:top_n]]\n",
        "        return top_guesses\n"
      ],
      "metadata": {
        "id": "K1qbi4QXQpSG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def show_board(board):\n",
        "    \"\"\"\n",
        "    Print unrevealed board words (as the human would see them).\n",
        "    \"\"\"\n",
        "    unrevealed = [w for w, rev in board.revealed.items() if not rev]\n",
        "    print(\"\\nCurrent Board Words:\")\n",
        "    for i, word in enumerate(unrevealed, 1):\n",
        "        print(f\"{i:2d}. {word}\")\n",
        "    print(\"-\" * 30)\n",
        "\n",
        "board = game_board  # or board = test_board\n",
        "show_board(board)\n",
        "\n",
        "clue_input = input(\"Enter your clue (format: word number): \").strip()\n",
        "if not clue_input:\n",
        "    raise RuntimeError(\"No clue provided.\")\n",
        "parts = clue_input.split()\n",
        "clue_word = parts[0]\n",
        "try:\n",
        "    clue_number = int(parts[1])\n",
        "except (IndexError, ValueError):\n",
        "    raise ValueError(\"Clue format invalid. Please provide a word and a number (e.g., 'tree 2').\")\n",
        "\n",
        "guessed_words = guesser.guess_words(clue_word, clue_number, board)\n",
        "print(\"AI guesses:\", guessed_words)\n",
        "\n",
        "for guess in guessed_words:\n",
        "    board.reveal_word(guess)\n",
        "    role = board.get_role(guess)\n",
        "    print(f\"Guessed '{guess}' -> {role.upper()}\")\n",
        "    if role == \"assassin\" or role == \"red\":\n",
        "        print(\"❌ End of turn!\")\n",
        "        break\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HSi0wbeNQy7-",
        "outputId": "5d36086b-b614-402a-b1cc-178ddf1d76f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Current Board Words:\n",
            " 1. gobbler\n",
            " 2. profusion\n",
            " 3. pericardial\n",
            " 4. tea\n",
            " 5. ascendent\n",
            " 6. investiture\n",
            " 7. colic\n",
            " 8. decapoda\n",
            " 9. valorous\n",
            "10. larch\n",
            "11. roble\n",
            "12. mimic\n",
            "13. nonconformist\n",
            "14. algeria\n",
            "15. bikini\n",
            "16. rapture\n",
            "17. paspalum\n",
            "18. slickly\n",
            "19. bosomy\n",
            "20. caldron\n",
            "21. grapple\n",
            "22. willebrand\n",
            "------------------------------\n",
            "Enter your clue (format: word number): drink 1\n",
            "AI guesses: ['tea']\n",
            "Guessed 'tea' -> BLUE\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Alzy-caiQ2wZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}